=== Data Model

The Genie 4 data model contains several modifications and additions to the data models from Genie
https://netflix.github.io/genie/concepts/2/DataModel.html[2] and
https://netflix.github.io/genie/docs/3.3.9/reference/#_data_model[3] to enable even more flexibility,
modularity and meta data retention. This section will go over the purpose of the various resources available from the
Genie API and how they interact.

==== Caveats

* The specific resource fields are *NOT* defined in this document. These fields are available in the
https://netflix.github.io/genie/docs/{revnumber}/rest/[REST API documentation]

==== Resources

The following sections describe the various resources available from the Genie REST APIs. You should reference the
https://netflix.github.io/genie/docs/{revnumber}/rest/[API Docs] for how to manipulate these resources. These sections
will focus on the high level purposes for each resource and how they rely and/or interact with other resources within
the system.


===== Configuration Resources

The following resources (applications, commands and clusters) are considered configuration, or admin, resources.
They're generally set up by the Genie administrator and available to all users for user with their jobs.

====== Application Resource

An application resource represents pretty much what you'd expect. It is a reusable set of binaries, configuration files
and setup files that can be used to install and configure (surprise!) an application. Generally these resources are
necessary when an application isn't already installed and on the `PATH` of the host running the job.

When a job is run the job Genie will download all the dependencies, configuration files and
setup files of each application and cluster and store it all in the job working directory. It will then
execute the setup script in order to install that application for that job. Genie is "dumb" as to the contents or
purpose of any of these files so the onus is on the administrators to create and test these packages.

Applications are very useful for decoupling application binaries from a Genie deployment. For example you could deploy
a Genie cluster and change the version of Hadoop, Hive, Spark that Genie will download without actually re-deploying
Genie. Applications can be combined together via a command. This will be explained more in the Command section.

The first entity to talk about is an application. Applications are linked to commands in order for binaries and
configurations to be downloaded and installed at runtime. Within Netflix this is frequently used to deploy new clients
without redeploying a Genie cluster.

At Netflix our applications frequently consists of a zip of all the binaries uploaded to s3 along with a setup file to
unzip and configure environment variables for that application.

====== Command Resource

Commands resources primarily represent what a user would enter at the command line if you wanted to run a process on a
cluster and what binaries (i.e., applications) you would need on your PATH to make that possible.

Commands can have configuration, setup and dependencies files just like applications but primarily they should have an ordered list
of applications associated with them if necessary. For example, lets take a typical scenario involving running Hive. To
run Hive you generally need a few things:

. A cluster to run its processing on (we'll get to that in the Cluster section)
. A hive-site.xml file which says what metastore to connect to amongst other settings
. Hive binaries
. Hadoop configurations and binaries

So a typical setup for Hive in Genie would be to have one, or many, Hive commands configured. Each command would have
its own hive-site.xml pointing to a specific metastore (prod, test, etc). Alternatively, site-specific configuration
can be associated to clusters and will be available to all commands executing against it.
The command would depend on Hadoop and Hive applications already configured which would have all the default
Hadoop and Hive binaries and configurations. All this would be combined in the job working directory in order to run Hive.

You can have any number of commands configured in the system. They should then be linked to the clusters they can
execute on. Clusters are explained next.

====== Cluster

A cluster stores all the details of an execution cluster including connection information, properties, etc. Some
cluster examples are Hadoop, Spark, Presto, etc. Every cluster can be linked to a set of commands that it can run.

Genie does *not* launch clusters for you. It merely stores metadata about the clusters you have running in your
environment so that jobs using commands and applications can connect to them.

Once a cluster has been linked to commands your Genie instance is ready to start running jobs. The job resources are
described in the following section. One important thing to note is that the list of commands linked to the cluster
is a priority ordered list. That means if you have two pig commands available on your system for the same cluster the
first one found in the list will be chosen provided all tags match. See <<How it Works>> for more details.

===== Tagging

An important concept is the tagging of resources. Genie relies heavily on tags for how the system discovers
resources like clusters and commands for a job. Each of the core resources has a set of tags that can be associated
with them. These tags can be of set to whatever you want but it is recommended to come up with some sort of consistent
structure for your tags to make it easier for users to understand their purpose. For example at Netflix we've adopted
some of the following standards for our tags:

* `sched:{something}`
** This corresponds to any schedule like that this resource (likely a cluster) is expected to adhere to
** e.g. `sched:sla` or `sched:adhoc`
* `type:{something}`
** e.g. `type:yarn` or `type:presto` for a cluster or `type:hive` or `type:spark` for a command
* `ver:{something}`
** The specific version of said resource
** e.g. two different Spark commands could have `ver:1.6.1` vs `ver:2.0.0`
* `data:{something}`
** Used to classify the type of data a resource (usually a command) will access
** e.g. `data:prod` or `data:test`

===== Job Resources

The following resources all relate to a user submitting and monitoring a given job. They are split up from the Genie 2
Job idea to provide better separation of concerns as usually a user doesn't care about certain things. What node a
job ran on or its Linux process exit code for example.

Users interact with these entities directly though all but the initial job request are *read-only* in the sense you can
only get their current state back from Genie.

====== Job Request

This is the resource you use to kick off a job. It contains all the information the system needs to run a job.
Optionally the REST APIs can take attachments. All attachments and file dependencies are downloaded into the root of
the jobs working directory. The most important aspects are the command line arguments, the cluster criteria and the
command criteria. These dictate the which cluster, command and arguments will be used when the job is executed. See the
<<How it Works>> section for more details.

====== Job

The job resource is created in the system after a Job Request is received. All the information a typical user would be
interested in should be contained within this resource. It has links to the command, cluster and applications used to
run the job as well as the meta information like status, start time, end time and others. See the
https://netflix.github.io/genie/docs/{revnumber}/rest/[REST API documentation] for more details.

====== Job Execution

The job execution resource contains information about where a job was run and other information that may be more
interesting to a system admin than a regular user. Frequently useful in debugging.

A job contains all the details of a job request and execution including any command line arguments. Based on the
request parameters, a cluster and command combination is selected for execution. Job requests can also supply necessary
files to Genie either as attachments or using the file dependencies field if they already exist in an accessible file
system. As a job executes, its details are recorded in the job record within the Genie database.

====== Resource configuration vs. dependencies

Genie allows associating files with the resources above so that these files are retrieved and placed in the job execution
directory as part of the setup.
When creating an Application, a Cluster, a Command or a Job, it is possible to associate *configs* and/or *dependencies*.
*Configs* are expected to be small configuration files (XML, JSON, YAML, ...), whereas *dependencies* are expected to be
larger and possibly binary (Jars, executables, libraries, etc).
Application, Cluster, and Command dependencies are deleted after job completion (unless Genie is configured to preserve
them), to avoid storing and archiving them over and over. Configurations are preserved. Job configurations and
dependencies are also preserved.

==== Wrap-up

This section was intended to provide insight into how the Genie data model is thought out and works together. It is
meant to be very generic and support as many use cases as possible without modifications to the Genie codebase.
